{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba79d419",
   "metadata": {},
   "source": [
    "# Web Scraping GitHub Topics\n",
    "\n",
    "## Introduction to Web Scraping\n",
    "Web scraping is a technique used to automatically extract data from websites. It allows developers to collect and analyze data from web pages by parsing their HTML or XML content. This technique is particularly useful for gathering large amounts of data from publicly accessible websites efficiently.\n",
    "\n",
    "## Introduction to GitHub and Problem Statement\n",
    "GitHub is a widely used platform for hosting and sharing code repositories. It features a \"Topics\" page where various technologies, frameworks, and languages are categorized to help users discover relevant projects. \n",
    "\n",
    "The goal of this project is to scrape the top topics listed on GitHub’s Topics page and store the information—such as topic titles, descriptions, and URLs—in a CSV file. This will provide an organized way to analyze and explore popular topics on GitHub.\n",
    "\n",
    "## Tools and Technologies Used\n",
    "\n",
    "### Python\n",
    "Python is a versatile programming language that is commonly used for web scraping due to its simplicity and the availability of powerful libraries.\n",
    "\n",
    "### Requests\n",
    "`requests` is a Python library that allows you to send HTTP requests to websites and retrieve their content. It simplifies the process of making web requests and handling responses.\n",
    "\n",
    "### Beautiful Soup\n",
    "`Beautiful Soup` is a Python library used to parse HTML and XML documents. It provides tools for navigating the document tree, searching for specific elements, and extracting data.\n",
    "\n",
    "### Pandas\n",
    "`Pandas` is a powerful Python library for data manipulation and analysis. It is used to structure the scraped data and save it in a CSV format.\n",
    "\n",
    "## Python Code for Web Scraping GitHub Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72aa085",
   "metadata": {},
   "source": [
    "Here are the steps we'll follow:\n",
    "\n",
    "- We're going to scrape https://github.com/topics\n",
    "- We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n",
    "- For each topic, we'll get the `top 20 repositories` in the topic from the topic page\n",
    "- For each repository, we'll grab the `repo name`, `username`, `stars` and `repo URL`\n",
    "- For each topic we'll create a CSV file in the following format:\n",
    "\n",
    "```\n",
    "Repo Name,Username,Stars,Repo URL\n",
    "three.js,mrdoob,69700,https://github.com/mrdoob/three.js\n",
    "libgdx,libgdx,18300,https://github.com/libgdx/libgdx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1302fd",
   "metadata": {},
   "source": [
    "## Scrape the list of topics from Github\n",
    "\n",
    "### To scrape the list of topics from GitHub, we'll follow these steps:\n",
    "\n",
    "- <b>Download the Page</b>: We'll use the requests library to send an `HTTP GET` request to the GitHub Topics page and download the `HTML` content of the page.\n",
    "- <b>Parse and Extract Information</b>: Once we have the HTML content, we'll use the `Beautiful Soup` library to parse the page and extract the relevant information such as topic titles, descriptions, and URLs.\n",
    "- <b>Convert to a Pandas DataFrame</b>: After extracting the data, we'll structure it in a `Pandas DataFrame` for easy manipulation and export it as a `CSV` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab801a",
   "metadata": {},
   "source": [
    "#### Install the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df4edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requests --upgrade --quiet\n",
    "\n",
    "# !pip install beautifulsoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d950be6",
   "metadata": {},
   "source": [
    "#### Import these libraries in python script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758efe5b",
   "metadata": {},
   "source": [
    "### Let's write a function to download the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f2aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_page():\n",
    "    # TODO - add comments\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4b50c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topics_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f6e26c",
   "metadata": {},
   "source": [
    "## Let's create some helper functions to parse information from the page.\n",
    "\n",
    "To get topic <b>titles</b>, we can pick `p` tags with the `class` ...\n",
    "\n",
    "![](https://i.imgur.com/M5padE4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d6c060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text)\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec16c5",
   "metadata": {},
   "source": [
    "`get_topic_titles` can be used to get the list of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd821074",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = get_topic_titles(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d47f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4d58a8",
   "metadata": {},
   "source": [
    "To get topic <b>descriptions</b>, we can pick `p` tags with the `class` ...\n",
    "\n",
    "![](https://i.imgur.com/70g2ugX.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_descs(doc):\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
    "    topic_descs = []\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "    return topic_descs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f14dd8b",
   "metadata": {},
   "source": [
    "`get_topic_descs` can be used to get the list of descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8e460",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = get_topic_descs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5573c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cbbd72",
   "metadata": {},
   "source": [
    "To get topic <b>URLs</b>, we can pick `\"a\"` tags with a `base url` and the `class` ...\n",
    "\n",
    "![](https://i.imgur.com/leQ9G0b.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763cedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_urls(doc):\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-1 d-flex flex-column'})\n",
    "    topic_urls = []\n",
    "    base_url = 'https://github.com'\n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760e4160",
   "metadata": {},
   "source": [
    "`get_topic_urls` can be used to get the list of URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c448c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = get_topic_urls(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571fd66",
   "metadata": {},
   "source": [
    "## Let's put this all together into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85444a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    topics_dict = {\n",
    "        'title': get_topic_titles(doc),\n",
    "        'description': get_topic_descs(doc),\n",
    "        'url': get_topic_urls(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_table = scrape_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53e331d",
   "metadata": {},
   "source": [
    "#### Getting a DataFrame of the topics_url with fields: `title`, `description` and `url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2714ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c005b5f",
   "metadata": {},
   "source": [
    "## Getting the top repositories from a topic page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690e90a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    # Download the page\n",
    "    response = requests.get(topic_url)\n",
    "    # Check successful response\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    # Parse using Beautiful soup\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7b7308",
   "metadata": {},
   "source": [
    "<b>Getting the topic page for the url:</b> `https://github.com/topics/3d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915135a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_url = url[0]\n",
    "\n",
    "print(custom_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_doc = get_topic_page(custom_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42fb5d",
   "metadata": {},
   "source": [
    "To get <b>repo tags</b>, we can pick `h3` tags with the `class` ...\n",
    "\n",
    "![](https://i.imgur.com/B6HDspK.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a19fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "repo_tags = topic_doc.find_all('h3',h3_selection_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4406c6",
   "metadata": {},
   "source": [
    "#### Getting the `username` for the first repository in `3d` topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30554c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1bc489",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tags = repo_tags[0].find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tags[0].text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8cdf05",
   "metadata": {},
   "source": [
    "#### Getting the `stars` for the same repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062248fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_tags = topic_doc.find_all('span', { 'class': 'Counter js-social-count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_tags[0].text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93595fe9",
   "metadata": {},
   "source": [
    "In the data, the value `101k` represents a shorthand notation commonly used to indicate large numbers, where `K` stands for `thousand`. To make this data easier to process and analyze, we converted the shorthand `101k` into its full numerical equivalent, `101000`.<br>\n",
    "Converting shorthand notation to a fixed numerical value ensures that all values are in a consistent numerical format, facilitating accurate calculations and comparisons.<br>\n",
    "The `parse_star_count` function does the conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb622f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star_count(stars_str):\n",
    "    stars_str = stars_str.strip()\n",
    "    if stars_str[-1] == 'k':\n",
    "        return int(float(stars_str[:-1]) * 1000)\n",
    "    return int(stars_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_star_count(star_tags[0].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91243def",
   "metadata": {},
   "source": [
    "### Getting all the required information about a repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://github.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61316048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(h3_tag, star_tag):\n",
    "    # returns all the required info about a repository\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url =  base_url + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef3ec8d",
   "metadata": {},
   "source": [
    "#### Getting the `username`,`repository name`,`stars` and `repository url` for the first repository in `3d` topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e168ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = get_repo_info(repo_tags[0],star_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eea0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38657710",
   "metadata": {},
   "source": [
    "## Getting all the topic repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124468b",
   "metadata": {},
   "source": [
    "The dictionary `topic_repos_dict` is designed to store information about repositories under a specific topic.<br>\n",
    "Each key in the dictionary represents a list that will hold specific details about the repositories. \n",
    "<br>Here’s a description of each key:\n",
    "- `username`: A list to store the GitHub usernames of the owners of the repositories.\n",
    "- `repo_name`: A list to store the names of the repositories.\n",
    "- `stars`: A list to store the number of stars each repository has received. Stars are a measure of how popular or well-regarded a repository is on GitHub.\n",
    "- `repo_url`: A list to store the URLs of the repositories, allowing users to directly access them on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38508c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_repos_dict = {\n",
    "    'username': [],\n",
    "    'repo_name': [],\n",
    "    'stars': [],\n",
    "    'repo_url': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7522bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_repos(topic_doc):\n",
    "    # Get the h3 tags containing repo title, repo URL and username\n",
    "    h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.find_all('h3', {'class': h3_selection_class} )\n",
    "    # Get star tags\n",
    "    star_tags = topic_doc.find_all('span', { 'class': 'Counter js-social-count'})\n",
    "    \n",
    "    topic_repos_dict = { 'username': [], 'repo_name': [], 'stars': [],'repo_url': []}\n",
    "\n",
    "    # Get repo info\n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "        \n",
    "    return pd.DataFrame(topic_repos_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06dc2db",
   "metadata": {},
   "source": [
    "The `scrape_topic` function you've provided is designed to scrape repository data from a specific GitHub topic page and save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8078e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic(topic_url, path):\n",
    "    if os.path.exists(path):\n",
    "        print(\"The file {} already exists. Skipping...\".format(path))\n",
    "        return\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c7b1a",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "- We have a funciton to get the list of topics\n",
    "- We have a function to create a CSV file for scraped repos from a topics page\n",
    "- Let's create a function to put them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1602e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics')\n",
    "    topic_df = scrape_topics()\n",
    "    \n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    for index, row in topic_df.iterrows():\n",
    "        print('Scraping top repositories for \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'], 'data/{}.csv'.format(row['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22fd8f7",
   "metadata": {},
   "source": [
    "Let's run it to scrape the top repos for the all the topics on the first page of https://github.com/topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8c4aa7",
   "metadata": {},
   "source": [
    "#### We can check that the CSVs were created properly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
